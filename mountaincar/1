import numpy as np
from grid import grid
from car import car

gamma=0.5
epoch=10000
grids=grid()
states=grids.states
rewards=grids.init()
start=[0,0]
mu=0
policy=np.zeros([grids.y_max, grids.x_max])


agent=car(grid=rewards, states=states)
print(agent.state[0], agent.state[1])
print(rewards)

for i in range(epoch):
	for j in range(epoch):
		reward=agent.move(action=policy[agent.state[0], agent.state[1]])
		mu = mu + (gamma**j) * reward
	
mu=mu/i
print(mu)
	
